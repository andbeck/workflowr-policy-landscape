---
title: "7_For_and_not_for_profit_comparison_part_2"
author: "ZZ, APB, TFJ"
# author: "zuzannazagrodzka"
date: "`r Sys.Date()`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# R Step and Packages

```{r, message=FALSE}
# Clearing R
rm(list=ls())

# Libraries used for text/data analysis
library(tidyverse) 
library(dplyr)
library(tidytext)

# Libraries used to create plots
library(ggplot2)

# Library to create a table when converting to html
library("kableExtra") 

# Library to read an arrow file
library(arrow)

```


# Import data
add column based on the name of the journal if its OA run by for profit or not-for-profit: 

- for_profit_no_oa:
"BioSciences", "Biological Conservation", "Conservation Biology", "Ecological Applications","Ecology Letters", "Ecology", "Frontiers in Ecology and the Environment", "Global Change Biology", "Journal of Applied Ecology", "Nature Ecology and Evolution", "Trends in Ecology & Evolution"

- no_profit_no_oa:
"American Naturalist", "Annual Review of Ecology Evolution and Systematics", "Evolution", "Philosophical Transactions of the Royal Society B", "Proceedings of the Royal Society B Biological Sciences"

- for_profit_oa:
"Arctic, Antarctic, and Alpine Research", "Biogeosciences", "Conservation Letters", "Diversity and Distributions", "Ecology and Evolution", "Evolutionary Applications", "Neobiota", "PeerJJournal"

- no_profit_oa:
"Ecology and Society", "Evolution Letters", "Frontiers in Ecology and Evolution", "Plos Biology", "Remote Sensing in Ecology and Conservation", "eLifeJournal"


# Importing data

```{r}

# Importing dataset created in "1a_Data_preprocessing.Rmd"
# df_corpuses <- read.csv(file = "./output/created_datasets/cleaned_data.csv")

# Importing dataset that we originally created and used in our analysis
df_corpuses <- read_feather(file = "./data/original_dataset_reproducibility_check/original_cleaned_data.arrow")

data_words <- df_corpuses

# Dictionary data 
# Importing dictionary data that we originally created and used in our analysis
all_dict <- read.csv(file = "./data/original_dataset_reproducibility_check/original_freq_dict_total_all.csv")

```

# Data Prep and Cleaning

``` {r}
# Data preparation

# Changing name of the dictionary variable
new_dictionary <- all_dict

## Getting a data set with the words
data_words <- df_corpuses

dim(data_words)
colnames(data_words)
unique(data_words$org_subgroups)
# Merging and removing duplicates
data_words <- data_words %>% 
  rename(document = name) %>% 
  select(document, org_subgroups, word) %>% 
  left_join(new_dictionary, by = c("word" = "word")) %>% # merging
  filter(org_subgroups %in% c("journals_nonOA", "journals_OA"))

data <- data_words

# Adding a column with a new variable
data$profit_access <- data$document

data$profit_access[data$profit_access%in% c("BioSciences", "Biological Conservation", "Conservation Biology", "Ecological Applications","Ecology Letters", "Ecology", "Frontiers in Ecology and the Environment", "Global Change Biology", "Journal of Applied Ecology", "Nature Ecology and Evolution", "Trends in Ecology & Evolution")] <- "for_profit_no_oa"

data$profit_access[data$profit_access%in% c("American Naturalist", "Annual Review of Ecology Evolution and Systematics", "Evolution", "Philosophical Transactions of the Royal Society B", "Proceedings of the Royal Society B Biological Sciences")] <- "no_profit_no_oa"

data$profit_access[data$profit_access%in% c("Arctic, Antarctic, and Alpine Research", "Biogeosciences", "Conservation Letters", "Diversity and Distributions", "Ecology and Evolution", "Evolutionary Applications", "Neobiota", "PeerJJournal")] <- "for_profit_oa"

data$profit_access[data$profit_access%in% c("Ecology and Society", "Evolution Letters", "Frontiers in Ecology and Evolution", "Plos Biology", "Remote Sensing in Ecology and Conservation", "eLifeJournal")] <- "no_profit_oa"


# # Check that all rows were replaced
# 
# check <- data
# 
# check <- check %>%
#   select(profit_access) %>%
#   group_by_all() %>%
#   summarise(COUNT = n())
# check

data_words <- data
```



```{r}

# Adding a column with the type of journal and word together to allow merging later
data_words$stake_word <- paste(data_words$profit_access, "_", data_words$word)
# Adding a column with a document name and word together to allow merging later
data_words$doc_word <- paste(data_words$document, "_", data_words$word)
# Adding a column that will be used later to calculate the total of unique words in the document (dictionaries without removed words)
data_words$doc_pres <- 1

# Adding two columns that will be used later to calculate the total of unique words in the document (new dictionaries with removed common words)
# Replace NAs with 0 in all absence/presence columns
data_words_ND <- data_words %>%
  mutate_at(vars(present_BUS, present_UNESCO, present_book, sum), ~replace_na(., 0)) # replacing NAs
  
head(data_words_ND,3)
colnames(data_words_ND)

## Preparing columns used to creating ternary plots
# Select columns of my interest (stakeholders) and aggregate 
  
data_words_ND <- data_words_ND %>% 
  select(document, profit_access, word, present_BUS, present_UNESCO, present_book, doc_pres, sum) # selecting columns, sum - column with the information about in how many dictionaries a certain word occurs

df_sum_pres_ND <- aggregate(x = data_words_ND[,4:8], by = list(data_words_ND$document), FUN = sum, na.rm = TRUE)
  
# By doing aggregate I lost info about the org_subgroups the doc come from, I want to add it
df_doc_ord <- data_words_ND %>% 
  select(document, profit_access) %>% 
  distinct(document, .keep_all = TRUE)
  
df_sum_pres_ND <- df_sum_pres_ND %>% 
  left_join(df_doc_ord, by = c("Group.1" = "document")) %>% 
  rename(document = Group.1)

# Creating % columns in a new df_sum_proc_ND data frame 
df_sum_proc_ND <- df_sum_pres_ND
# View(df_sum_proc_ND)

df_sum_proc_ND$proc_BUS <-df_sum_proc_ND$present_BUS/df_sum_proc_ND$doc_pres*100
df_sum_proc_ND$proc_UNESCO <- df_sum_proc_ND$present_UNESCO/df_sum_proc_ND$doc_pres*100
df_sum_proc_ND$proc_book <- df_sum_proc_ND$present_book/df_sum_proc_ND$doc_pres*100


# Additional information about the data
# Stakeholders (2 from each of the stakeholders) that shared the highest no of words with UNESCO recommendation

UNESCO_stak_top <- df_sum_proc_ND %>% 
  group_by(profit_access) %>% 
  arrange(desc(proc_UNESCO)) %>% 
  slice_head(n=2) %>% 
  select(profit_access, document, proc_UNESCO)

UNESCO_stak_top %>% 
  kbl(caption = "Stakeholders that shared the higest no of words with UNESCO recommendation:") %>% 
  kable_classic("hover", full_width = T)

# Stakeholders (2 from each of the stakeholders) that shared the highest no of words with business dictionary

business_stak_top <- df_sum_proc_ND %>% 
  group_by(profit_access) %>% 
  arrange(desc(proc_BUS)) %>% 
  slice_head(n=2) %>% 
  select(profit_access, document, proc_BUS)

business_stak_top %>% 
  kbl(caption = "Stakeholders that shared the higest no of words with business dictionary:") %>% 
  kable_classic("hover", full_width = T)

# Stakeholders (2 from each of the stakeholders) that shared the highest no of words with book dictionary (control)

book_stak_top <-  df_sum_proc_ND %>% 
  group_by(profit_access) %>% 
  arrange(desc(proc_book)) %>% 
  slice_head(n=2) %>% 
  select(profit_access, document, proc_book)

book_stak_top %>% 
  kbl(caption = "Stakeholders that shared the higest no of words with book dictionary (control):") %>% 
  kable_classic("hover", full_width = T)

```

# Creating graphs

```{r}
no <- nrow(df_sum_proc_ND)
no

# Plotting them separately book
df_sum_proc_ND_book = data.frame(
  document = rep(df_sum_proc_ND$document,1),
  profit_access = rep(df_sum_proc_ND$profit_access,1),
  type = c(rep("Book",no)),
  perc = c(df_sum_proc_ND$proc_book),
  perc2 = c(df_sum_proc_ND$proc_book))

sum_df_sum_proc_ND_book = 
  df_sum_proc_ND_book %>%
  group_by(profit_access, type) %>%
  # dplyr::summarise(perc = mean(perc), SD = sd(perc2))
  dplyr::summarise(perc = median(perc), SD = sd(perc2))

fig_book <- ggplot() +
  geom_point(data = df_sum_proc_ND_book, aes(x = perc, y = profit_access), alpha = 0.1, position = position_jitter()) +
  geom_pointrange(data = sum_df_sum_proc_ND_book, aes(x = perc, xmin = perc - SD, xmax = perc + SD, y = profit_access)) +
  facet_grid(type~.) +
  labs(x = "Document words occuring in dictionary (%)", y = "") +
  scale_colour_discrete(guide = "none") +
  theme_classic()

fig_book

# Saving the figure
# UNCOMMENT TO SAVE THE FIGURE
figure_name <- paste0("./output/Figure_4C/Figure_4C_book.png")
ggsave(filename = figure_name, fig_book  + theme_bw(base_size = 5),
     width = 10, height = 5, dpi = 600, units = "in", device='png')


# Plotting them separately Business
df_sum_proc_ND_BUS = data.frame(
  document = rep(df_sum_proc_ND$document,1),
  profit_access = rep(df_sum_proc_ND$profit_access,1),
  type = c(rep("Business",no)),
  perc = c(df_sum_proc_ND$proc_BUS),
  perc2 = c(df_sum_proc_ND$proc_BUS))

sum_df_sum_proc_ND_BUS = 
  df_sum_proc_ND_BUS %>%
  group_by(profit_access, type) %>%
  # dplyr::summarise(perc = mean(perc), SD = sd(perc2))
  dplyr::summarise(perc = median(perc), SD = sd(perc2))

fig_bus <- ggplot() +
  geom_point(data = df_sum_proc_ND_BUS, aes(x = perc, y = profit_access), alpha = 0.1, position = position_jitter()) +
  geom_pointrange(data = sum_df_sum_proc_ND_BUS, aes(x = perc, xmin = perc - SD, xmax = perc + SD, y = profit_access)) +
  facet_grid(type~.) +
  labs(x = "Document words occuring in dictionary (%)", y = "") +
  scale_colour_discrete(guide = "none") +
  theme_classic()

fig_bus

# Saving the figure
# UNCOMMENT TO SAVE THE FIGURE
figure_name <- paste0("./output/Figure_4C/Figure_4C_bus.png")
ggsave(filename = figure_name, fig_bus  + theme_bw(base_size = 5),
     width = 10, height = 5, dpi = 600, units = "in", device='png')



# Plotting them separately UNESCO
df_sum_proc_ND_UNESCO = data.frame(
  document = rep(df_sum_proc_ND$document,1),
  profit_access = rep(df_sum_proc_ND$profit_access,1),
  type = c(rep("UNESCO",no)),
  perc = c(df_sum_proc_ND$proc_UNESCO),
  perc2 = c(df_sum_proc_ND$proc_UNESCO))

sum_df_sum_proc_ND_UNESCO = 
  df_sum_proc_ND_UNESCO %>%
  group_by(profit_access, type) %>%
  # dplyr::summarise(perc = mean(perc), SD = sd(perc2))
  dplyr::summarise(perc = median(perc), SD = sd(perc2))

fig_unesco <- ggplot() +
  geom_point(data = df_sum_proc_ND_UNESCO, aes(x = perc, y = profit_access), alpha = 0.1, position = position_jitter()) +
  geom_pointrange(data = sum_df_sum_proc_ND_UNESCO, aes(x = perc, xmin = perc - SD, xmax = perc + SD, y = profit_access)) +
  facet_grid(type~.) +
  labs(x = "Document words occuring in dictionary (%)", y = "") +
  scale_colour_discrete(guide = "none") +
  theme_classic()

fig_unesco

# Saving the figure
# UNCOMMENT TO SAVE THE FIGURE
figure_name <- paste0("./output/Figure_4C/Figure_4C_unesco.png")
ggsave(filename = figure_name, fig_unesco  + theme_bw(base_size = 5),
     width = 10, height = 5, dpi = 600, units = "in", device='png')

```


# Session information
``` {r}
sessionInfo()
```



